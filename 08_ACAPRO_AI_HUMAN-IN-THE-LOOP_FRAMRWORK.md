# AcaPro AI Human-in-the-Loop Framework

**Document ID:** 08_HUMAN_IN_LOOP  
**Standard:** 2026 Skill / Agent Platform  
**Status:** Constitutional Specification  
**Applies To:** All human oversight, approval, override, and accountability mechanisms within the AcaPro AI platform  
**Effective Date:** 20 January 2026 (Melbourne Time)

---

## 1. Purpose of Human-in-the-Loop

This document defines the **Human-in-the-Loop (HITL) Framework** of the AcaPro AI platform.

Its purpose is to:

- Preserve human authority in high-impact educational decisions  
- Ensure accountability for AI-assisted outcomes  
- Prevent over-automation in high-risk learning contexts  
- Enable transparent collaboration between humans and AI Agents  

This document is binding under the authority of:

- `01_PLATFORM_CONSTITUTION.md`  
- `02_ARCHITECTURE_OVERVIEW.md`  
- `03_AGENT_SYSTEM.md`  
- `05_DECISION_ENGINE.md`  
- `07_RISK_CONTROL.md`  

---

## 2. Definition of Human-in-the-Loop

Within AcaPro AI, **Human-in-the-Loop** refers to:

> A mandatory governance mechanism  
> requiring qualified human review, approval, or override  
> before AI-assisted actions with material consequences are executed.

Human-in-the-Loop is a **structural requirement**, not a user preference.

---

## 3. Human Roles and Authority

The platform recognizes the following human roles:

- Educators and teachers  
- Institutional administrators  
- Parents or guardians (where applicable)  
- Learners themselves  

Each role has defined authority boundaries and visibility rights.

No AI component may override human authority.

---

## 4. Scenarios Requiring Human Involvement

Human involvement is mandatory for:

- High-risk academic guidance  
- Curriculum acceleration or delay  
- Assessment interpretation with long-term impact  
- Subject or pathway selection  
- Any irreversible educational decision  

Low-risk scenarios MAY proceed without human intervention.

---

## 5. Human Approval Model

For decisions requiring approval:

- AI MUST present a structured rationale  
- Risk classification MUST be explicit  
- Uncertainty and confidence limits MUST be disclosed  
- Alternative options MUST be visible  

Human approval is an affirmative action, not passive acceptance.

---

## 6. Human Override Rights

Humans retain the right to:

- Override AI recommendations  
- Reject AI outputs entirely  
- Modify AI-suggested actions  
- Suspend automated execution  

Override actions MUST be logged and reviewable.

AI systems MUST adapt to overrides without resistance.

---

## 7. Visibility and Explainability

For all human-reviewed decisions, the platform MUST provide:

- Clear explanation of reasoning  
- Invoked Agents and Skills  
- Data sources and versions  
- Identified risks and constraints  

Opaque or non-explainable outputs are prohibited.

---

## 8. Learner Agency and Consent

Learners retain agency over their learning journey.

The platform MUST:

- Inform learners when AI assistance is used  
- Respect consent requirements where applicable  
- Allow learners to question or decline AI guidance  

AI assistance MUST NOT coerce or manipulate learner behavior.

---

## 9. Logging and Audit of Human Actions

All human-in-the-loop interactions MUST be logged, including:

- Approval or rejection decisions  
- Overrides and modifications  
- Timestamp and role identity  
- Associated AI outputs and risk levels  

Human action logs are part of the official audit trail.

---

## 10. Conflict Resolution

In cases of disagreement between:

- AI recommendations  
- Different human reviewers  

The platform MUST:

- Defer execution  
- Escalate to higher authority where defined  
- Preserve all dissenting inputs  

Forced consensus is prohibited.

---

## 11. Safeguards Against Automation Bias

The platform MUST implement safeguards to:

- Prevent over-reliance on AI recommendations  
- Encourage independent human judgment  
- Surface uncertainty and alternative interpretations  

Human judgment MUST remain primary.

---

## 12. Training and Qualification

Humans exercising approval or override authority MUST:

- Be appropriately qualified  
- Understand the scope and limits of AI assistance  
- Receive guidance on interpreting AI outputs  

Unqualified approval is prohibited.

---

## 13. Compliance and Enforcement

All Human-in-the-Loop processes MUST comply with:

- Platform Constitution  
- Decision Engine rules  
- Risk Control requirements  
- Data Governance policies  

Non-compliance may result in:

- Suspension of automated workflows  
- Restriction of AI capabilities  
- Mandatory review and remediation  

---

## 14. Foundational Statement

AI may assist learning.

Humans remain responsible  
for decisions, outcomes,  
and the welfare of learners.
